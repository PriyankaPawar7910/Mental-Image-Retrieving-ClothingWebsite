# Mental-Image-Retrieving-ClothingWebsite
—Image-based clothing retrieval is receiving increasing interest with the growth of online shopping. In practice, users may often have a desired piece of clothing in mind (e.g., either having seen it before on the street or requiring certain speciﬁc clothing attributes) but may be unable to supply an image as a query. We model this problem as a new type of image retrieval task in which the target image resides only in the user’s mind (called “mental image retrieval” hereafter). Because of the absence of an explicit query image, we propose to solve this problem through relevance feedback. Speciﬁcally, a newBayesianformulationisproposedthatsimultaneouslymodels the retrieval target and its high-level representation in the mind of the user (called the “user metric” hereafter) as posterior distributions of pre-fetched shop images and heterogeneous features extracted from multiple clothing attributes, respectively. Requiring only clicks as user feedback, the proposed algorithm is able to account for the variability in human decision-making. Experiments with real users demonstrate the effectiveness of the proposed algorithm. 
